{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 252A Computer Vision I Fall 2019 - Homework 2\n",
    "### Instructor: Ben Ochoa\n",
    "### Assignment Published On: Tuesday, October 8, 2019\n",
    "### Due On: Tuesday, October 22, 2019 11:59 pm\n",
    "\n",
    "## Instructions\n",
    "* Review the academic integrity and collaboration policies on the course website.\n",
    "* This assignment must be completed individually.\n",
    "* All solutions must be written in this notebook\n",
    "* Programming aspects of this assignment must be completed using Python in this notebook.\n",
    "* If you want to modify the skeleton code, you can do so. This has been provided just to provide you with a framework for the solution.\n",
    "* You may use python packages for basic linear algebra (you can use numpy or scipy for basic operations), but you may not use packages that directly solve the problem.\n",
    "* If you are unsure about using a specific package or function, then ask the instructor and teaching assistants for clarification.\n",
    "* You must submit this notebook exported as a pdf. You must also submit this notebook as .ipynb file.\n",
    "* You must submit both files (.pdf and .ipynb) on Gradescope. You must mark each problem on Gradescope in the pdf.\n",
    "* It is highly recommended that you begin working on this assignment early.\n",
    "* **Late policy - Assignments submitted late will receive a 15% grade reduction for each 12 hours late (i.e., 30% per day). Assignments will not be accepted 72 hours after the due date. If you require an extension (for personal reasons only) to a due date, you must request one as far in advance as possible. Extensions requested close to or after the due date will only be granted for clear emergencies or clearly unforeseeable circumstances.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Perspective Projection and Homogenous Coordinates [10 pts]\n",
    "### Part 1 [5 pts]\n",
    "Consider a perspective projection where a point \n",
    "$$\n",
    "P = [\\text{x y z}]^T\n",
    "$$\n",
    "is projected onto an image plane $\\Pi'$ represented by $k = f'>0$ as shown in the following figure.\n",
    "![title](fig1.png)\n",
    "\n",
    "The first second and third coordinate axes are denoted by $i$, $j$, $k$ respectively. \n",
    "\n",
    "Consider the projection of two rays in the world coordinate system\n",
    "$$\n",
    "Q1 = [\\text{7 -3 1}] + t[\\text{8 2 4}]\n",
    "$$\n",
    "$$\n",
    "Q2 = [\\text{2 -5 9}] + t[\\text{8 2 4}]\n",
    "$$\n",
    "where $-\\infty \\leq t \\leq -1$. \n",
    "\n",
    "Calculate the coordinates of the endpoints of the projection of the rays onto the image plane. Identify the vanishing point based on the coordinates.  \n",
    "  \n",
    "### Part 2 [3 pts]\n",
    "Prove that all parallel lines have the same vanishing point.  \n",
    "\n",
    "### Part 3 [2 pts]\n",
    "Show that the use of homogenous coordinates can convert an affine transformation into that of a linear one. Recall that an affine transformation of any vector x is described by Ax + b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Image Formation and Rigid Body Transformations [10 points]\n",
    "\n",
    "In  this  problem  we  will  practice  rigid  body  transformations  and  image  formations  through  the projective camera model. The goal will be to photograph the following four points \n",
    "$$^AP_1 = [\\text{-1 -0.5 2}]^T$$,  $$^AP_2 = [\\text{1 -0.5 2}]^T$$, $$^AP_3 = [\\text{1 0.5 2}]^T$$, $$^AP_4 = [\\text{-1 0.5 2}]^T$$\n",
    "\n",
    "To do this we will need two matrices.  Recall, first, the following formula for rigid body transformation\n",
    "$$\n",
    "^BP = \\text{ } ^B_AR\\text{ }^AP + \\text{ } ^BO_A\n",
    "$$\n",
    "Where $^BP$ is the point coordinate in the target ($B$) coordinate system. $^AP$ is the point coordinate in the source ($A$) coordinate system. $^B_AR$ is the rotation matrix from $A$ to $B$, and $^BO_A$ is the origin of the coordinate system $A$ expressed in $B$ coordinates. \n",
    "\n",
    "The rotation and translation can be combined into a single 4 $\\times$ 4 extrinsic parameter matrix, $P_e$, so that $^BP = P_e \\cdot \\text{ }^AP$.\n",
    "\n",
    "Once transformed, the points can be photographed using the intrinsic camera matrix, $P_i$ which is a 3 $\\times$ 4 matrix.\n",
    "\n",
    "Once these are found, the image of a point, $^AP$, can be calculated as $P_i \\cdot P_e \\cdot \\text{ }^AP$.\n",
    "\n",
    "We will consider four different settings of focal length, viewing angles and camera positions below. For each of these calculate:\n",
    "\n",
    "a) Extrinsic transformation matrix,\n",
    "\n",
    "b) Intrinsic camera matrix under the perspective camera assumption.\n",
    "\n",
    "c) Calculate the image of the four vertices and plot using the supplied functions\n",
    "\n",
    "Your output should look something like the following image (Your output values might not match, this is just an example)\n",
    "\n",
    "\n",
    "![Sample Plots](new.png)\n",
    "\n",
    "1. [No rigid body transformation]. Focal  length  =  1. The  optical  axis  of  the  camera  is aligned with the z-axis.\n",
    "2. [Translation]. $^BO_A = [\\text{0 0 1}]^T$. Focal length = 1. The optical axis of the camera is aligned with the z-axis.\n",
    "3. [Translation and Rotation]. Focal length = 1. $^B_AR$ encodes a 30 degrees around the z-axis and then 60 degrees around the y-axis. $^BO_A = [\\text{0 0 1}]^T$.\n",
    "4. [Translation and Rotation, long distance]. Focal length = 5. $^B_AR$ encodes a 30 degrees around the z-axis and then 60 degrees around the y-axis. $^BO_A = [\\text{0 0 13}]^T$.\n",
    "\n",
    "> You can refer the Richard Szeliski starting page 36 for image formation and the extrinsic matrix.\n",
    "\n",
    "> Intrinsic matrix calculation for perspective camera models was covered in class and can be referred in slide 2  \n",
    "https://cseweb.ucsd.edu/classes/fa19/cse252A-a/lec2.pdf  \n",
    "> You can also refer lecture 3 of the previous year's course as well for further information if you wish!  \n",
    "http://cseweb.ucsd.edu/classes/fa18/cse252A-a/lec3.pdf \n",
    "\n",
    "We will not use a full intrinsic camera matrix (e.g.  that maps centimeters to pixels, and defines  the  coordinates  of  the  center  of  the  image),  but  only  parameterize  this  with $f$,  the  focal\n",
    "length.  In other words:  the only parameter in the intrinsic camera matrix under the perspective assumption is $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-9ea5181581e3>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-9ea5181581e3>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    def from_homog(points_homog):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "# convert points from euclidian to homogeneous\n",
    "def to_homog(points): #here always remember that points is a 3x4 matrix\n",
    "    # write your code here\n",
    "    \n",
    "\n",
    "\n",
    "# convert points from homogeneous to euclidian\n",
    "def from_homog(points_homog):\n",
    "    # write your code here\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# project 3D euclidian points to 2D euclidian\n",
    "def project_points(P_int, P_ext, pts):\n",
    "    # write your code here\n",
    "    \n",
    "        \n",
    "    return from_homog(pts_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the three matrices for the four cases as described in the problem\n",
    "# in the four camera functions geiven below. Make sure that we can see the formula\n",
    "# (if one exists) being used to fill in the matrices. Feel free to document with\n",
    "# comments any thing you feel the need to explain. \n",
    "\n",
    "def camera1():\n",
    "    # write your code here\n",
    "    \n",
    "    return P_int_proj, P_ext\n",
    "\n",
    "def camera2():\n",
    "    # write your code here\n",
    "    \n",
    "    return P_int_proj, P_ext\n",
    "\n",
    "def camera3():\n",
    "    # write your code here\n",
    "\n",
    "    return P_int_proj, P_ext\n",
    "\n",
    "def camera4():    \n",
    "    # write your code here\n",
    "    return P_int_proj, P_ext\n",
    "\n",
    "# Use the following code to display your outputs\n",
    "# You are free to change the axis parameters to better \n",
    "# display your quadrilateral but do not remove any annotations\n",
    "\n",
    "def plot_points(points, title='', style='.-r', axis=[]):\n",
    "    inds = list(range(points.shape[1]))+[0]\n",
    "    plt.plot(points[0,inds], points[1,inds],style)\n",
    "    \n",
    "    for i in range(len(points[0,inds])):\n",
    "        plt.annotate(str(\"{0:.3f}\".format(points[0,inds][i]))+\",\"+str(\"{0:.3f}\".format(points[1,inds][i])),(points[0,inds][i], points[1,inds][i]))\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    if axis:\n",
    "        plt.axis(axis)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "        \n",
    "def main():\n",
    "    point1 = np.array([[-1,-.5,2]]).T\n",
    "    point2 = np.array([[1,-.5,2]]).T\n",
    "    point3 = np.array([[1,.5,2]]).T\n",
    "    point4 = np.array([[-1,.5,2]]).T \n",
    "    points = np.hstack((point1,point2,point3,point4))\n",
    "    \n",
    "    for i, camera in enumerate([camera1, camera2, camera3, camera4]):\n",
    "        P_int_proj, P_ext = camera()\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plot_points(project_points(P_int_proj, P_ext, points), title='Camera %d Projective'%(i+1), axis=[-0.6,2.5,-0.75,0.75])\n",
    "        plt.show()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Homography [12 pts]\n",
    "\n",
    "Consider a vision application in which components of the scene are replaced by components from another image scene. \n",
    "\n",
    "In this problem, we will implement partial functionality of a smartphone camera scanning application (Example: CamScanner) that, in case you've never used before, takes pictures of documents and transforms it by warping and aligning to give an image similar to one which would've been obtained through using a scanner.\n",
    "\n",
    "The transformation can be visualized by imagining the use of two cameras forming an image of a scene with a document. The scene would be the document you're trying to scan placed on a table and one of the cameras would be your smart phone camera, forming the image that you'll be uploading and using in this assignment. There can also be an ideally placed camera, oriented in the world in such a way that the image it forms of the scene has the document perfectly algined. While it is unlikely you can hold your phone still enough to get such an image, we can use homography to transform the image you take into the image that the ideally placed camera would have taken.\n",
    "\n",
    "This digital replacement is accomplished by a set of corresponding points for the document in both the source (your picture) and target (the ideal) images. The task then consists of mapping the points from the source to their respective points in the target image. In the most general case, there would be no constraints on the scene geometry, making the problem quite hard to solve. If, however, the scene can be approximated by a plane in 3D, a solution can be formulated much more easily even without the knowledge of camera calibration parameters. \n",
    "\n",
    "To solve this section of the homework, you will begin by understanding the transformation that maps one image onto another in the planar scene case. Then you will write a program that implements this transformation and use it to warp some document into a well aligned document (See the given example to understand what we mean by well aligned).\n",
    "\n",
    "\n",
    "\n",
    "To begin with, we consider the projection of planes in images. imagine two cameras $C_1$ and $C_2$ looking at a plane $\\pi$ in the world. Consider a point $P$ on the plane $\\pi$ and its projection $p=[\\text{u1, v1, 1}]^T$ in the image 1 and $q=[\\text{u2, v2, 1}]^T$ in image 2.\n",
    "\n",
    "There exists a unique, upto scale, 3 $\\times$ 3 matrix $H$ such that, for any point $P$:\n",
    "$$q \\approx Hp$$\n",
    "Here $\\approx$ denotes equality in homogeneous coordinates, meaning that the left and right hand sides are proportional. Note that $H$ only depends on the plane and the projection matrices of the two cameras.\n",
    "\n",
    "The interesting thing about this result is that by using $H$ we can compute the image of $P$ that would be seen in the camera with center $C_2$ from the image of the point in the camera with center at $C_1$, without knowing the three dimensional location. Such an $H$ is a projective transformation of the plane, called a homography.\n",
    "\n",
    "In this problem, complete the code for computeH and warp functions that can be used in the skeletal code that follows. \n",
    "\n",
    "There are three warp functions to implement in this assignment, example ouputs of which are shown below. In warp1, you will create a homography from points in your image to the target image (Mapping source points to target points). In warp2, the inverse of this process will be done. In warp3, you will create a homography between a given image and your image, replacing your document with the given image.\n",
    "\n",
    "1. ![title](forward.png) \n",
    "2. ![title](inverse.png)  \n",
    "3. ![](backward.png)  \n",
    "\n",
    "1. In the context of this problem, the source image refers to the image of a document you take that needs to be replaced into the target. \n",
    "2. The target image can start out as an empty matrix that you fill out using your code.\n",
    "3. You will have to implement the computeH function that computes a homography. It takes in exactly four point correspondences between the source image and target image in homogeneous coordinates respectively and returns a 3 $\\times$ 3 homography matrix.\n",
    "4. You will also have to implement the three warp functions in the skeleton code given and plot the resultant image pairs. For plotting, make sure that the target image is not smaller than the source image.\n",
    "\n",
    "Note: We have provided test code to check if your implementation for computeH is correct. All the code to plot the results needed is also provided along with the code to read in the images and other data required for this problem. Please try not to modify that code. \n",
    "\n",
    "You may find following python built-ins helpful:\n",
    "numpy.linalg.svd, numpy.meshgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load image to be used - resize to make sure it's not too large\n",
    "# You can use the given image as well\n",
    "# A large image will make testing you code take longer; once you're satisfied with your result,\n",
    "# you can, if you wish to, make the image larger (or till your computer memory allows you to)\n",
    "\n",
    "source_image = np.array(Image.open(\"photo.jpg\"))/255\n",
    "\n",
    "# display images\n",
    "plt.imshow(source_image)\n",
    "\n",
    "# Align the polygon such that the corners align with the document in your picture\n",
    "# This polygon doesn't need to overlap with the edges perfectly, an approximation is fine\n",
    "# The order of points is clockwise, starting from bottom left.\n",
    "x_coords = [0,0,0,0] \n",
    "y_coords = [0,0,0,0]\n",
    "\n",
    "# Plot points from the previous problem is used to draw over your image \n",
    "# Note that your coordinates will change once you resize your image again\n",
    "source_points = np.vstack((x_coords, y_coords))\n",
    "plot_points(source_points)\n",
    "\n",
    "plt.show()\n",
    "print (source_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeH(source_points, target_points):\n",
    "    # returns the 3x3 homography matrix such that:\n",
    "    # np.matmul(H, source_points) = target_points\n",
    "    # where source_points and target_points are expected to be in homogeneous\n",
    "    # make sure points are 3D homogeneous\n",
    "    assert source_points.shape[0]==3 and target_points.shape[0]==3\n",
    "    #Your code goes here\n",
    "    \n",
    "    H_mtx = np.zeros((3,3)) #Fill in the H_mtx with appropriate values.\n",
    "\n",
    "    return  H_mtx\n",
    "#######################################################\n",
    "# test code. Do not modify\n",
    "#######################################################\n",
    "def test_computeH():\n",
    "    source_points = np.array([[0,0.5],[1,0.5],[1,1.5],[0,1.5]]).T\n",
    "    target_points = np.array([[0,0],[1,0],[2,1],[-1,1]]).T\n",
    "    H = computeH(to_homog(source_points), to_homog(target_points))\n",
    "    mapped_points = from_homog(np.matmul(H,to_homog(source_points)))\n",
    "    print (from_homog(np.matmul(H,to_homog(source_points[:,1].reshape(2,1)))))\n",
    "\n",
    "    plot_points(source_points,style='.-k')\n",
    "    plot_points(target_points,style='*-b')\n",
    "    plot_points(mapped_points,style='.:r')\n",
    "    plt.show()\n",
    "    print('The red and blue quadrilaterals should overlap if ComputeH is implemented correctly.')\n",
    "test_computeH()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp(source_img, source_points, target_size):\n",
    "    # Create a target image and select target points to create a homography from source image to target image,\n",
    "    # in other words map all source points to target points and then create\n",
    "    # a warped version of the image based on the homography by filling in the target image.\n",
    "    # Make sure the new image (of size target_size) has the same number of color channels as source image\n",
    "    assert target_size[2]==source_img.shape[2]\n",
    "    #Your code goes here\n",
    "    return target_img\n",
    "\n",
    "# Use the code below to plot your result\n",
    "result = warp(source_image, source_points, (0,0,0)) #Choose appropriate target size\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(source_image)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imsave(\"myop.png\",result)\n",
    "plt.imshow(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of warp1 of your code probably has some striations or noise. The larger you make your target image, the less it will resemble the document in the source image. Why is this happening? \n",
    "\n",
    "To fix this, implement warp2, by creating an inverse homography matrix and fill in the target image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp2(source_img, source_points, target_size):\n",
    "    # Create a target image and select target points to create a homography from target image to source image,\n",
    "    # in other words map each target point to a source point, and then create a warped version\n",
    "    # of the image based on the homography by filling in the target image.\n",
    "    # Make sure the new image (of size target_size) has the same number of color channels as source image\n",
    "    \n",
    "    #Your code goes here\n",
    "    return target_img\n",
    "\n",
    "# Use the code below to plot your result\n",
    "result = warp2(source_image, source_points, (0,0,0)) #Choose appropriate size\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(source_image)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(result)\n",
    "plt.imsave(\"warp2.png\",result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try playing around with the size of your target image in warp1 versus in warp2, additionally you can also implement nearest pixel interpolation or bi-linear interpolations and see if that makes a difference in your output.\n",
    "\n",
    "In warp3, you'll be replacing the document in your image with a provided image. Read in \"ucsd_logo.png\" as the source image, keeping your document as the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the given UCSD logo image\n",
    "\n",
    "def warp3(target_image, target_points, source_image):\n",
    "    #Your code goes here\n",
    "    return target_image\n",
    "\n",
    "\n",
    "# Use the code below to plot your result\n",
    "result1 = warp3(target_image, target_points, source_image)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(source_image2)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(result1)\n",
    "plt.imsave(\"warp3.png\",result1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Surface Rendering [18 pts]\n",
    "\n",
    "In this portion of the assignment we will be exploring different methods of approximating local illumination of\n",
    "objects in a scene. This last section of the homework will be an exercise in rendering surfaces. Here, you need use the surface normals and the masks from the provided pickle files, with various light sources, different materials, and using a number of illumination models. For the sake of simplicity, multiple reflections of light rays, and occlusion of light rays due to object/scene can be ignored.\n",
    "\n",
    "### Data\n",
    "\n",
    "The surface normals and masks are to be loaded from the respective pickle files. For comparison, You should display the rendering results for both normals calculated from the original image and the diffuse components. There are 2 images that we will be playing with namely one of a sphere and the other of a pear.\n",
    "\n",
    "Assume that the albedo map is uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambertian Illumination\n",
    "\n",
    "One of the simplest models available to render 3D objections with illumination is the Lambertian model. This\n",
    "model finds the apparent brightness to an observer using the direction of the light source $\\mathbf{L}$ and the normal\n",
    "vector on the surface of the object $\\mathbf{N}$. The brightness intensity at a given point on an object’s surface, $\\mathbf{I_d}$, with\n",
    "a single light source is found using the following relationship:\n",
    "\n",
    "$$\\mathbf{I_d} = \\mathbf{L} \\cdot \\mathbf{N} (I_l\\mathbf{C})$$\n",
    "\n",
    "where, $\\mathbf{C}$ and $I_l$ are the the color and intensity of the light source respectively.\n",
    "\n",
    "### Phong Illumination\n",
    "\n",
    "One major drawback of Lambertian illumination is that it only considers the diffuse light in its calculation of\n",
    "brightness intensity. One other major component to illumination rendering is the specular component. The\n",
    "specular reflectance is the component of light that is reflected in a single direction, as opposed to all directions,\n",
    "which is the case in diffuse reflectance. One of the most used models to compute surface brightness with specular\n",
    "components is the Phong illumination model. This model combines ambient lighting, diffused reflectance as well\n",
    "as specular reflectance to find the brightness on a surface. Phong shading also considers the material in the scene\n",
    "which is characterized by four values: the ambient reflection constant ($k_a$), the diffuse reflection constant ($k_d$),\n",
    "the specular reflection constant ($k_s$) and $\\alpha$ the Phong constant, which is the ‘shininess’ of an object. Furthermore,\n",
    "since the specular component produces ‘rays’, only some of which would be observed by a single observer, the\n",
    "observer’s viewing direction ($\\mathbf{V}$) must also be known. For some scene with known material parameters with $M$\n",
    "light sources the light intensity $\\mathbf{I}_{phong}$ on a surface with normal vector $\\mathbf{N}$ seen from viewing direction $\\mathbf{V}$ can be\n",
    "computed by:\n",
    "\n",
    "$$\\mathbf{I}_{phong} = k_{a}\\mathbf{I}_{a} + \\sum_{m\\in M}\\left\\{k_d(\\mathbf{L}_{m}\\cdot\\mathbf{N})\\mathbf{I}_{m,d} + k_{s}(\\mathbf{R}_{m}\\cdot\\mathbf{V})^{\\alpha}\\mathbf{I}_{m,s}\\right\\}\\text{,}$$\n",
    "\n",
    "$$\\mathbf{R}_{m} = 2\\mathbf{N}(\\mathbf{L}_{m}\\cdot\\mathbf{N}) - \\mathbf{L}_{m}\\text{,}$$\n",
    "\n",
    "where $\\mathbf{I}_{a}$, is the color and intensity of the ambient lighting, $\\mathbf{I}_{m,d}$ and $\\mathbf{I}_{m,s}$ are the color values for the diffuse and\n",
    "specular light of the $m$th light source.\n",
    "\n",
    "### Rendering\n",
    "\n",
    "Please complete the following:\n",
    "\n",
    "1. Write the function `lambertian()` that calculates the Lambertian light intensity given the light direction $\\mathbf{L}$ with color and intensity $\\mathbf{C}$ and $I_l = 1$, and normal vector $\\mathbf{N}$. Then use this function in a program that calculates and displays the specular sphere and the pear using each of the two lighting sources found in Table 1. *Note: You do not need to worry about material coefficients in this model.*\n",
    "\n",
    "1. Write the function `phong()` that calculates the Phong light intensity given the material constants $(k_a, k_d, k_s, \\alpha)$, $\\mathbf{V} = (0, 0, 1)^\\top$, $\\mathbf{N}$ and some number of $M$ light sources. Then use this function in a program that calculates and displays the specular sphere and the pear using each of the sets of coefficients found in Table 2 with each light source individually, and both light sources combined.\n",
    "\n",
    "*Hint: To avoid artifacts due to shadows, ensure that any negative intensities found are set to zero.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Table 1: Light Sources\n",
    "\n",
    "| $m$ | Location | Color (RGB)  |\n",
    "| - | ----------- | ----- |\n",
    "| 1 | $(-\\tfrac{1}{3},\\tfrac{1}{3},\\tfrac{1}{3})^{\\top}$ | $(1,1,1)$ |\n",
    "| 2 | $(1,0,0)^{\\top}$     | $(1,.5,.5)$ |\n",
    "\n",
    "Table 2: Material Coefficients\n",
    "\n",
    "| Mat. | $k_a$ | $k_d$ | $k_s$ | $\\alpha$ |\n",
    "| - | -------- | ----- | ----- | -------- |\n",
    "| 1 | $0$ | $0.1$ | $0.75$ | $5$ |\n",
    "| 2 | $0$ | $0.5$ | $0.1$ | $5$ |\n",
    "| 3 | $0$ | $0.5$ | $0.5$ | $10$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Loading pickle files and plotting the normals [4 pts] (Sphere - 2pts, Pear - 2pts)\n",
    "In this first part, you are required to work with 2 images, one of a sphere and the other one of a pear. The pickle file normals.pickle is a list consisting of 4 numpy matrices which are    \n",
    "1) Normal Vectors for the sphere with specularities removed (Diffuse component)  \n",
    "2) Normal Vector for the sphere    \n",
    "3) Normal Vectors for the pear with specularities removed (Diffuse component)  \n",
    "4) Normal vectors for the pear  \n",
    "Please load the normals and plot them using the function plot_normals which is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_normals(diffuse_normals, original_normals):\n",
    "    # Stride in the plot, you may want to adjust it to different images\n",
    "    stride = 5\n",
    "    \n",
    "    normalss = diffuse_normals\n",
    "    normalss1 = original_normals\n",
    "    \n",
    "    print(\"Normals:\")\n",
    "    print(\"Diffuse\")\n",
    "    # showing normals as three separate channels\n",
    "    figure = plt.figure()\n",
    "    ax1 = figure.add_subplot(131)\n",
    "    ax1.imshow(normalss[..., 0])\n",
    "    ax2 = figure.add_subplot(132)\n",
    "    ax2.imshow(normalss[..., 1])\n",
    "    ax3 = figure.add_subplot(133)\n",
    "    ax3.imshow(normalss[..., 2])\n",
    "    plt.show()\n",
    "    print(\"Original\")\n",
    "    figure = plt.figure()\n",
    "    ax1 = figure.add_subplot(131)\n",
    "    ax1.imshow(normalss1[..., 0])\n",
    "    ax2 = figure.add_subplot(132)\n",
    "    ax2.imshow(normalss1[..., 1])\n",
    "    ax3 = figure.add_subplot(133)\n",
    "    ax3.imshow(normalss1[..., 2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the normals for the sphere and pear for both the normal and diffuse components.\n",
    "#1 : Load the different normals\n",
    "# LOAD HERE\n",
    "\n",
    "#2 : Plot the normals using plot_normals\n",
    "#What do you observe? What are the differences between the diffuse component and the original images shown?\n",
    "\n",
    "#PLOT HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Lambertian model [6 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in your implementation for the rendered image using the lambertian model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    assert img.shape[2] == 3\n",
    "    maxi = img.max()\n",
    "    mini = img.min()\n",
    "    return (img - mini)/(maxi-mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambertian(normals, lights, color, intensity, mask):\n",
    "    '''Your implementation'''\n",
    "    image = np.ones((normals.shape[0], normals.shape[1], 3))\n",
    "    return (image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the rendered results for both the sphere and the pear for both the original and the diffuse components. Remember to first load the masks from the masks.pkl file. The masks.pkl file is a list consisting of 2 numpy arrays-  \n",
    "1)Mask for the sphere  \n",
    "2)Mask for the pear  \n",
    "Remember to plot the normalized image using the function normalize which is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the masks for the sphere and pear\n",
    "# LOAD HERE\n",
    "\n",
    "# Output the rendering results for Pear\n",
    "dirn1 = np.array([[1.0],[0],[0]])\n",
    "color1 = np.array([[1],[.5],[.5]])\n",
    "dirn2 = np.array([[-1.0/3],[1.0/3],[1.0/3]])\n",
    "color2 = np.array([[1],[1],[1]])\n",
    "\n",
    "#Display the rendering results for pear for both diffuse and for both the light sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the rendering results for Sphere\n",
    "dirn1 = np.array([[1.0],[0],[0]])\n",
    "color1 = np.array([[1],[.5],[.5]])\n",
    "dirn2 = np.array([[-1.0/3],[1.0/3],[1.0/3]])\n",
    "color2 = np.array([[1],[1],[1]])\n",
    "#Display the rendering results for sphere for both diffuse and for both the light sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Phong model [8 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in your implementation for the Phong model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phong(normals, lights, color, material, view, mask):\n",
    "    '''Your implementation'''\n",
    "    return (image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function completed, plot the rendering results for the sphere and pear (both diffuse and original compnents) for all the materials and light sources and also with the combination of both the light sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the rendering results for sphere\n",
    "view =  np.array([[0],[0],[1]])\n",
    "material = np.array([[0.1,0.75,5],[0.5,0.1,5],[0.5,0.5,10]])\n",
    "lightcol1 =  np.array([[-1.0/3,1],[1.0/3,1],[1.0/3,1]])\n",
    "lightcol2 = np.array([[1,1],[0,0.5],[0,0.5]])\n",
    "#Display rendered results for sphere for all materials and light sources and combination of light sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the rendering results for the pear.\n",
    "view =  np.array([[0],[0],[1]])\n",
    "material = np.array([[0.1,0.75,5],[0.5,0.1,5],[0.5,0.5,10]])\n",
    "lightcol1 =  np.array([[-1.0/3,1],[1.0/3,1],[1.0/3,1]])\n",
    "lightcol2 = np.array([[1,1],[0,0.5],[0,0.5]])\n",
    "#Display rendered results for pear for all materials and light sources and combination of light sources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
